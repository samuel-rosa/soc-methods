---
title: "Pedotransfer functions for prediction and harmonization of carbon and organic matter content data in southern Brazil: source code"
author: "Alessandro Samuel-Rosa"
date: "20 July 2018"
url: "https://docs.google.com/document/d/13CJdr6huHhpuwKMfz_u03m8dJE3_xLqhmS7lwc5Y5yE/edit?usp=sharing"
output: html_document
---

```{r}
# load packages
library(dplyr)
library(magrittr)
library(latticeExtra)
library(glue)
library(raster)
library(gdalUtils)
library(TeachingDemos)
```

# Material and Methods

## Soil data

The data can be downloaded from the Free Brazilian Repository for Open Soil Data. The dataset identification 
code is `ctb0029`. Here we use a copy of the data stored in folder `data`.

```{r}
if (file.exists("../data/camada.rda")) {
  load("../data/camada.rda")
} else {
  camada <- febr::layer("ctb0029", variable = "all")
  save(camada, file = "../data/camada.rda")
}
if (file.exists("../data/observacao.rda")) {
  load("../data/observacao.rda")
} else {
  observacao <- febr::observation("ctb0029", variable = "all")
  save(observacao, file = "../data/observacao.rda")
}
```

We create categorical variables using the clay content (`argila_naoh_esferas_pipeta`) and the organic matter
content determined at the commercial soil analysis laboratory of the Universidade Federal de Santa Maria
(`matorg_dicromato_30min80_eam`). For the latter, the classification is performed using the three classes used 
for fertilizer recommendations in Rio Grande do Sul and Santa Catarina. For convenience, we rename key soil
variables using short English names.

```{r, echo=FALSE, message=FALSE}
# camada <- readr::read_csv(
  # '../data/camada.csv', locale = readr::locale(decimal_mark = ','), comment = '#unidade', na = "-")
camada <-
  camada %>% 
  mutate(textura = ifelse(argila_naoh_esferas_pipeta <= 250, '0-250', '251-500')) %>% 
  mutate(textura = ifelse(argila_naoh_esferas_pipeta > 500, '501-1000', textura)) %>% 
  mutate(textura = as.factor(textura)) %>% 
  mutate(matorg = ifelse(matorg_dicromato_30min80_eam <= 25, '<25', '26-50')) %>%
  mutate(matorg = ifelse(matorg_dicromato_30min80_eam > 50, '>50', matorg)) %>%
  mutate(matorg = as.factor(matorg)) %>% 
  mutate(observacao_id = as.factor(observacao_id)) %>% 
  rename(clay = argila_naoh_esferas_pipeta) %>% 
  rename(toc = carbono_fornalha_1min950_cgdct) %>%
  rename(oc = carbono_dicromato_30min150_mohr) %>% 
  rename(tom = matorg_fornalha_120min360_massa) %>% 
  rename(om = matorg_dicromato_30min80_eam) %>% 
  mutate(profund_sup = as.numeric(profund_sup)) %>% 
  mutate(profund_inf = as.numeric(profund_inf))
camada
```

Data on soil observations if processed. Land use info, `terra_usoatual`, is reclassified using FAO guidelines 
for soil description. The following codes are used:

* FS (Floresta): Semi-deciduous forest (vegetation slightly disturbed)
* U (Vegetação secundária): Not used and not managed, vegetation strongly disturbed by clearing, burning,
  ploughing (secondary vegetation, mix of semi-deciduous shrubs and tall grassland)
* AA (Agricultura): Annual field cropping
* FP (Silvicultura): Plantation forestry
* HE (Campo nativo): Animal husbandry (extensive grazing)

Soil taxa is recoded for plotting purposes using a lookup table downloaded from the Free Brazilian Repository
for Open Soil Data

```{r, echo=FALSE, message=FALSE}
sibcs <- readr::read_csv('../data/tabela-de-consulta.csv')
sibcs_recode <- as.list(sibcs$campo_codigo)
names(sibcs_recode) <- sibcs$campo_nome
# observacao <- readr::read_csv(
  # '../data/observacao.csv', locale = readr::locale(decimal_mark = ','), comment = '#unidade', na = '-')
observacao <-
  observacao %>% 
  arrange(observacao_id) %>% 
  mutate(terra_usoatual = gsub('Floresta', 'FS', .data$terra_usoatual)) %>% 
  mutate(terra_usoatual = gsub('Vegetação secundária', 'U', .data$terra_usoatual)) %>%
  mutate(terra_usoatual = gsub('Agricultura', 'AA', .data$terra_usoatual)) %>%
  mutate(terra_usoatual = gsub('Silvicultura', 'FP', .data$terra_usoatual)) %>%
  mutate(terra_usoatual = gsub('Campo nativo', 'HE', .data$terra_usoatual)) %>% 
  mutate(taxon = recode(taxon_sibcs_2009, !!!sibcs_recode))
observacao
```

We create new categorical predictor variables using data on land use (forest, agriculture, grazing), sampling
depth (topsoil), and taxonomy (latossolo, argissolo, cambissolo, planossolo, neossolo). These are dummy 
variables composed of zeros and ones. Also, rows of the dataset not containing soil carbon / organic matter 
data are eliminated.

```{r}
camada <- camada[1:105, ]
camada <- 
  camada %>% 
  mutate(terra_usoatual = observacao$terra_usoatual) %>% 
  mutate(forest = ifelse(terra_usoatual == "FS", 1, 0)) %>% 
  mutate(agriculture = ifelse(terra_usoatual == "AA", 1, 0)) %>% 
  mutate(grazing = ifelse(terra_usoatual == "HE", 1, 0)) %>% 
  dplyr::select(-terra_usoatual) %>% 
  mutate(topsoil = ifelse(profund_inf <= 20, 1, 0)) %>% 
  mutate(taxon2 = observacao$taxon_sibcs_2009) %>% 
  mutate(taxon1 = sapply(taxon2, function (x) unlist(strsplit(x, " "))[1])) %>% 
  mutate(latossolo = ifelse(taxon1 == "Latossolo", 1, 0)) %>% 
  mutate(argissolo = ifelse(taxon1 == "Argissolo", 1, 0)) %>% 
  mutate(cambissolo = ifelse(taxon1 == "Cambissolo", 1, 0)) %>% 
  mutate(planossolo = ifelse(taxon1 == "Planossolo", 1, 0)) %>% 
  mutate(neossolo = ifelse(taxon1 == "Neossolo", 1, 0)) %>% 
  dplyr::select(-taxon1, -taxon2)
camada
```

Compute some summary statistics: number of taxonomic classes, and range of clay content.

```{r, eval = FALSE}
data.frame(
  taxa = nlevels(as.factor(observacao$taxon)),
  min_clay = min(camada$clay, na.rm = TRUE),
  max_clay = max(camada$clay, na.rm = TRUE)
  )
```

### Figure 1

Study area and locations (municipalities) where soil samples were taken.

We first download the necessary data to prepare the figure. This includes shapefiles of the limits of the 
state of Rio Grande do Sul and water masses (Atlantic Ocean and lakes), obtained from IBGE geoservices, and a
digital elevation model of the state of Rio Grande do Sul, prepared by the Geoprocessing Laboratory of the
Federal University of Rio Grande do Sul. We also process the observations, so that a single observation from
each municipality is ploted.

```{r, fig.asp=1}
if (!file.exists("../data/rs.shp")) {
  gdalUtils::ogr2ogr(
    src_datasource_name = "WFS:http://www.geoservicos.ibge.gov.br:80/geoserver/wfs", 
    dst_datasource_name = "../data/rs.shp",
    layer = "CGEO:C02_limite_estadual_2010")
} else {
  rs <- shapefile("../data/rs.shp")
}
if (!file.exists("../data/rs.zip")) {
  download.file(
    "http://www.ecologia.ufrgs.br/labgeo/arquivos/downloads/dados/SRTM/geotiff/rs.zip",
    destfile = "../data/rs.zip")
  unzip("../data/rs.zip", exdir = "../data/")
}
if (!file.exists("../data/lagos.shp")) {
  gdalUtils::ogr2ogr(
    src_datasource_name = "WFS:http://www.geoservicos.ibge.gov.br:80/geoserver/wfs", 
    dst_datasource_name = "../data/lagos.shp",
    layer = "CGEO:ANMS2010_03_massa_dagua",
    where = "nome_massa = 'Lagoa dos Patos' OR nome_massa = 'Lagoa Mangueira' OR nome_massa = 'Lagoa Mirum'")
} else {
  lagos <- shapefile("../data/lagos.shp")
}
if (!file.exists("../data/oceano.shp")) {
  gdalUtils::ogr2ogr(
    src_datasource_name = "WFS:http://www.geoservicos.ibge.gov.br:80/geoserver/wfs", 
    dst_datasource_name = "../data/oceano.shp",
    layer = "CCAR:BCIM_Massa_Dagua_A",
    where = "nome = 'Oceano Atlântico'")
} else {
  oceano <- shapefile("../data/oceano.shp")
}
gdalUtils::gdal_translate(
  src_dataset = "../data/rs.tif", dst_dataset = "../data/rs1km.tif", tr = c(1000, 1000) / 111120)
gdalUtils::gdaldem(
  mode = "hillshade", input_dem = "../data/rs1km.tif", output = "../data/hillshade1km.tif", 
  alg = "ZevenbergenThorne", z = 40, s = 111120)
dem <- raster("../data/rs1km.tif")
hill <- raster("../data/hillshade1km.tif")
oceano <- oceano %>% crop(extent(dem))
```

```{r, fig.asp=1}
png("../res/fig/study-area.png", width = 480 * 2.29, height = 480 * 2, res = 72 * 2)
col <- terrain.colors(24, alpha = 0.50)
plot(hill, col = grey(0:100/100), legend = FALSE, ylab = "Latitude, °", xlab = "Longitude, °")
plot(dem, col = col, add = TRUE, 
     legend.args = list(text = '                 Elevation, m', line = 1, side = 3, font = 2, cex = 0.8))
plot(rs[rs$NomUF == "Rio Grande do Sul", ], add = TRUE)
plot(lagos, add = TRUE, col = "lightblue")
plot(oceano, add = TRUE, col = "lightblue")
observacao %>% 
  filter(!duplicated(municipio_id)) %>% 
  dplyr::select(coord_x, coord_y) %>% 
  points(bg = "firebrick", col = "ivory", pch = 21)
TeachingDemos::shadowtext(x = -56.1, y = -28.1, labels = "Argentina", srt = 50)
TeachingDemos::shadowtext(x = -55.5, y = -31.7, labels = "Uruguay", srt = -43)
TeachingDemos::shadowtext(x = -50.5, y = -27.7, labels = "Santa Catarina", srt = -38)
TeachingDemos::shadowtext(
  x = coordinates(oceano)[1] + 0.5, y = coordinates(oceano)[2] + 0.5, labels = "Atlantic Ocean")
TeachingDemos::shadowtext(
  x = coordinates(rs[rs$NomUF == "Rio Grande do Sul", ])[1],
  y = coordinates(rs[rs$NomUF == "Rio Grande do Sul", ])[2] + 0.5, labels = "Rio Grande do Sul")
rect(xleft = -51, ybottom = extent(dem)[3], xright = extent(dem)[2], ytop = -32, col = "white", 
     border = "black")
par(fig = c(0.73, 0.77, 0.17, 0.21), new = TRUE)
col <- rep("white", length(rs))
col[rs$NomUF == "Rio Grande do Sul"] <- "firebrick"
plot(rs, add = TRUE, col = col)
dev.off()
```

### Figure 2

Key characteristics of the soil samples, such as the clay content and sampling depth, and their sampling sites,
such as the soil classification and type of land use and occupation.

```{r, eval = FALSE}
p1 <- histogram(
  ~ clay, camada, xlab = expression('Clay content, g kg'^'-1'), ylab = 'Percent of total', 
  col = 'lightgray',
  panel = function (...) {
    lattice::panel.grid(v = -1, h = -1)
    lattice::panel.histogram(...)
  },
  page = function (n) {
    grid::grid.text(label = "A)", x = grid::unit(0.04, "npc"), y = grid::unit(0.95, "npc"))
  }) +
  latticeExtra::layer(panel.abline(v = c(250, 500), lty = 'dotted'))
p2 <- histogram(
  ~ profund_sup, camada, xlab = 'Sampling depth, cm', ylab = 'Percent of total', col = 'lightgray',
  panel = function (...) {
    lattice::panel.grid(v = -1, h = -1)
    lattice::panel.histogram(...)
  },
  page = function (n) {
    grid::grid.text(label = "B)", x = grid::unit(0.04, "npc"), y = grid::unit(0.95, "npc"))
  })
p3 <- barchart(
  observacao$taxon, xlab = 'Soil classification', ylab = 'Percent of total', horizontal = FALSE, 
  col = 'lightgray', scales = list(x = list(rot = 60)),
  panel = function (...) {
    lattice::panel.grid(h = -1, v = 0)
    lattice::panel.barchart(...)
  },
  page = function (n) {
    grid::grid.text(label = "C)", x = grid::unit(0.04, "npc"), y = grid::unit(0.95, "npc"))
  })
p4 <- barchart(
  observacao$terra_usoatual, xlab = 'Land use and ocupation', ylab = 'Percent of total', horizontal = FALSE, 
  col = 'lightgray',
  panel = function (...) {
    lattice::panel.grid(h = -1, v = 0)
    lattice::panel.barchart(...)
  },
  page = function (n) {
    grid::grid.text(label = "D)", x = grid::unit(0.04, "npc"), y = grid::unit(0.95, "npc"))
  })
png("../res/fig/features-soil-samples.png", width = 480 * 4, height = 480 * 4, res = 72 * 3)
gridExtra::grid.arrange(p1, p2, p3, p4, ncol = 2)
dev.off()
```

## Analytical methods

Includes a description of the four analytical methods used:

1. Total organic carbon (TOC) by dry combustion
2. Organic carbon (OC) by wet digestion
3. Organic matter (OM) by wet digestion
4. Total organic matter (TOM) by loss on ignition

### Figure 3

Empirical probability density of carbon (A and B) and organic matter (C and D) content in soil samples 
according to the four analytical methods and the theoretical normal probability density function (dashed line).

```{r, eval = FALSE}
l <- layer(
  panel.mathdensity(
    dmath = dnorm, args = list(mean = mean(x, na.rm = TRUE), sd = sd(x, na.rm = TRUE)), n = length(x), 
    col = 'black', lty = 'dashed'))
p1 <- histogram(
  ~ toc, camada, 
  xlab = expression('Total organic carbon (TOC), g kg'^'-1'), col = 'lightgray', type = "density", 
  panel = function (...) {
    panel.grid(v = -1, h = -1)
    panel.histogram(...)
  },
  page = function (n) {
    grid::grid.text(label = "A)", x = grid::unit(0.04, "npc"), y = grid::unit(0.95, "npc"))
  }) + l
p2 <- histogram(
  ~ oc, camada, 
  xlab = expression('Organic carbon (OC), g kg'^'-1'), col = 'lightgray', type = "density", 
  panel = function (...) {
    panel.grid(v = -1, h = -1)
    panel.histogram(...)
  },
  page = function (n) {
    grid::grid.text(label = "B)", x = grid::unit(0.04, "npc"), y = grid::unit(0.95, "npc"))
  }) + l
p3 <- histogram(
  ~ om, camada, 
  xlab = expression('Organic matter (OM), g dm'^'-3'), col = 'lightgray', type = "density", 
  panel = function (...) {
    panel.grid(v = -1, h = -1)
    panel.histogram(...)
  },
  page = function (n) {
    grid::grid.text(label = "C)", x = grid::unit(0.04, "npc"), y = grid::unit(0.95, "npc"))
  }) + l
p4 <- histogram(
  ~ tom, camada, 
  xlab = expression('Total organic matter (TOM), g kg'^'-1'), col = 'lightgray', type = "density", 
  panel = function (...) {
    panel.grid(v = -1, h = -1)
    panel.histogram(...)
  },
  page = function (n) {
    grid::grid.text(label = "D)", x = grid::unit(0.04, "npc"), y = grid::unit(0.95, "npc"))
  }) + l
png("../res/fig/carbon-histograms.png", width = 480 * 4, height = 480 * 4, res = 72 * 3)
gridExtra::grid.arrange(p1, p2, p3, p4, ncol = 2)
dev.off()
```

# Pedotransfer functions

## Model formulation

We test six model formulations, starting with predictor variables that are more readly available and ending 
with the most complex/expensive model. These are:

A. y ~ 0 + x
B. y ~ 1 + x
C. y ~ 1 + x + x^2
D. y ~ 1 + x + x^2 + topsoil
E. y ~ 1 + x + x^2 + topsoil + landuse
F. y ~ 1 + x + x^2 + topsoil + landuse + clay
G. y ~ 1 + x + x^2 + topsoil + landuse + clay + taxon

In models F and G, 'clay' is used to compose interaction terms with 'x' and 'x^2'.

```{r}
# Soil variables
soil_vars <- c("toc", "oc", "om", "tom")
soil_vars <- expand.grid(soil_vars, soil_vars, stringsAsFactors = FALSE)[, 2:1]
soil_vars <- soil_vars[!soil_vars[, 1] == soil_vars[, 2], ]

# Predictor variables
landuse <- "agriculture + forest + grazing"
taxon <- "argissolo + cambissolo + latossolo + neossolo + planossolo"

# Formulas
formulas <- lapply(1:nrow(soil_vars), function (i) {
  y <- soil_vars[i, 1]
  x <- soil_vars[i, 2]
  list(
    glue("{y} ~ 0 + {x}"), # A
    glue("{y} ~ {x}"), # B
    glue("{y} ~ {x} + I({x}^2)"), # C
    glue("{y} ~ {x} + I({x}^2) + topsoil"), # D
    glue("{y} ~ {x} + I({x}^2) + topsoil + {landuse}"), # E
    glue("{y} ~ {x}*clay + I({x}^2)*clay + topsoil + {landuse}"), # F
    glue("{y} ~ {x}*clay + I({x}^2)*clay + topsoil + {landuse} + {taxon}") # G
    )
})
names(formulas) <- sapply(formulas, function (x) x[[1]])
```

## Model estimation

We use weighted least squares (WLS) to estimate model parameters. Below, we test the implementation of WLS to
estimate the betas, make predictions and estimate prediction error variances. Estimates are compared with the
output of `lm` and `predict.lm`. This toy exercise is usefull to understand the estimation equations and their
differences compared to ordinary least squares.

```{r, eval=FALSE}
# Temporary data
tmp_data <- camada

# Test observations
i <- 96:105

# Estimate model using lm
fit <- lm(tom ~ om + clay, data = tmp_data[-i, ], weights = 1/om)
pred <- predict(fit, tmp_data[i, c("om", "clay")], se.fit = TRUE)

# Dependent variable
Y <- tmp_data[-i, "tom"] %>% as.matrix()

# Predictor variables
X <- data.frame(x0 = 1, tmp_data[-i, c("om", "clay")]) %>% as.matrix()

# Weights
W <- matrix(0, ncol = nrow(X), nrow = nrow(X))
diag(W) <- 1 / X[, "om"]

# Estimate betas: (X'WX)⁻¹X'WY
b_hat <- solve(t(X) %*% W %*% X) %*% t(X) %*% W %*% Y %>% drop()
data.frame(b_hat = b_hat, lm = fit$coefficients)

# Residual sum of squares
rss <- sum(diag(W) * (Y - X %*% drop(b_hat))^2) / (nrow(X) - ncol(X))
data.frame(rss, lm = summary(fit)$sigma^2)

# Prediction at a point
x0 <- data.frame(x0 = 1, tmp_data[i, c("om", "clay")]) %>% as.matrix()
y_hat <- x0 %*% drop(b_hat)
data.frame(y_hat = y_hat, lm = pred$fit)

# Prediction error variance: RSS * (1 + x0 (X'WX)⁻¹x0')
pev <- rss * (1 + x0 %*% solve(t(X) %*% W %*% X) %*% t(x0)) %>% diag()
data.frame(pev = pev, lm = pred$se.fit^2 + pred$residual.scale^2)
```

## Model validation

Run leave-one-out cross-validation and compute performance measures:

* MedE: median error
* MedSE: median squared error
* MedAE: median absolute error
* MedSDR: median squared deviation ratio
* AVE: amount of variation explained (or model efficiency)
* mAVE: modified amount of variation explained (or modified model efficiency)

The median is used instead of the mean because it is less sensitive to outliers.

# Results

## Carbon and organic matter data

### Figure 4

Scatter plot matrix of the soil carbon and organic matter content measured using four different analytical 
methods and their relation to the total clay content and class (0-250, 251-500, 501-1000 g kg-1). The solid 
line represents a perfect 1:1 linear relation, while the dashed line is the observed empirical linear relation
between variables.

```{r, eval = FALSE}
# outliers <- c(58, 74, 66, 69, 70, 101, 102, 103, 105)
png("../res/fig/scatter-plot-matrix.png", width = 480 * 4, height = 480 * 4, res = 72 * 3)
p1 <- 
  camada %>% 
  dplyr::select(toc, oc, om, tom, clay) %>% 
  splom(groups = camada$textura, grid = TRUE, auto.key = list(columns = 3), xlab = '',
        varnames = c(expression(atop('TOC', 'g kg'^'-1')), expression(atop('OC', 'g kg'^'-1')),
                     expression(atop('OM', 'g dm'^'-3')), expression(atop('TOM', 'g kg'^'-1')),
                     expression(atop('Clay', 'g kg'^'-1')))) +
  latticeExtra::layer(panel.abline(a = 0, b = 1)) +
  latticeExtra::layer(panel.lmline(x = x, y = y, lty = 'dashed'))
# Potential outliers
# p1 <- p1 + latticeExtra::layer(panel.text(x = x[outliers], y = y[outliers], outliers, pos = 1, cex = 0.7))
p1
dev.off()
```

Compute the linear correlation coeeficient between variables. This is used to discuss Figure 4.

```{r}
cor(camada[, c("toc", "oc", "om", "tom", "clay")]) %>% round(3)
```

```{r}
cor.test(camada$tom, camada$clay);cor.test(camada$om, camada$clay)
```

Compute the correlation between clay and TOM when TOM is very low (TOM < 50).

```{r}
cor.test(camada[camada$toc < 25, ]$tom, camada[camada$toc < 25, ]$clay)
cor.test(camada[camada$toc < 25, ]$toc, camada[camada$toc < 25, ]$clay)
```

## Prediction performance

Identify minimum and maximum values to define a criterion to scale performance measures (MedE, MedAE, and 
MedSE) so that they are comparable.

```{r}
camada %>% dplyr::select(tom, om, oc, toc) %>% sapply(min)
camada %>% dplyr::select(tom, om, oc, toc) %>% sapply(max)
```

```{r}
model_fit <- list()
cross_validation <- list()
# i <- 1
for (i in 1:length(formulas)) {
  
  forms <- formulas[[i]]
  y <- camada[[soil_vars[i, 1]]]
  resid <- mean(y) - y
  x <- camada[[soil_vars[i, 2]]]
  w <- 1 / x # weigths are inversely proportional to the predictor variable
  
  fit <- list()
  loocv <- list()
  # j <- 1
  for (j in 1:length(forms)) {
    f <- forms[[j]]
    
    # Record model fit summary
    fit[[j]] <- lm(formula = f, data = camada, weights = w) %>% summary()
    
    out <- data.frame(pred = NA_real_, pev = NA_real_)
    # Leave-one-out cross-validation
    # k <- 1
    for (k in 1:nrow(camada)) {
      # Weighted least squares regression
      lm_fit <- lm(formula = f, data = camada[-k, ], weights = w[-k])
      pred <- predict.lm(object = lm_fit, newdata = camada[k, ], se.fit = TRUE)
      out[k, ] <- c(pred$fit, pred$se.fit^2 + pred$residual.scale^2)
    }
    
    # Cross-validation statistics
    error <- out$pred - y
    error_sqr <- error * error
    error_abs <- abs(error)
    denom <- max(y) # scale measures 
    loocv[[j]] <- data.frame(
      
      # Model
      f = f,
      p = LETTERS[j] %>% as.factor(),
      y = soil_vars[i, 1],
      x = soil_vars[i, 2],
      m = glue("{soil_vars[i, 1]} ~ {soil_vars[i, 2]}") %>% toupper() %>% as.factor(),
      
      # Median error measures
      MedE = median(error) / denom,
      MedAE = median(error_abs) / denom,
      MedSE = median(error_sqr) / (denom * denom),
      # MedSDR = 1 - qchisq(p = 0.5, df = 1) + median(error_sqr / out$pev),
      MedSDR = median(error_sqr / out$pev),
      
      # Model efficiency
      AVE = 1 - (sum(error_sqr) / sum(resid * resid)),
      mAVE = 1 - (sum(error_abs) / sum(abs(resid))) # less sensitive to outliers than AVE
    )
  }
  names(fit) <- forms
  model_fit[[i]] <- fit
  cross_validation[[i]] <- do.call(rbind, loocv)
}
cross_validation <- do.call(rbind, cross_validation)
```

Prediction bias of the most complex models.

```{r}
cross_validation %>% filter(p == "G") %>% dplyr::select(MedE) %>% c()
```

Spread of prediction errors for TOC ~ OC and OC ~ TOC accross model formulations.

```{r}
cross_validation %>% filter(m == "TOC ~ OC" | m == "OC ~ TOC") %>% dplyr::select(MedSE, MedAE) %>% 
  summarise(mean(MedSE), mean(MedAE)) %>% round(3)
```

Spread of prediction errors for TOM ~ OC and TOM ~ TOC accross model formulations.

```{r}
cross_validation %>% filter(m == "TOM ~ OC" | m == "TOM ~ TOC") %>% filter(p == "A" | p == "G") %>% 
  dplyr::select(m, p, MedSE, MedAE)
```

### Figure 5

Leave-one-out cross-validation performance of PTFs estimated via WLS. Line color and type indicate the 
dependent and predictor variable, respectively. Measurement units of MedE, MedAE, and MedSE are g kg-1 -- for 
TOC, OC, and TOM -- and g dm-3 -- for OM, while MedSDR, AVE, and mAVE are unitless performance measures. Model
formulations are described in Table 2. Performance measures are defined in Table 3.

```{r, fig.asp=1}
col <- c("dodgerblue", "magenta", "olivedrab", "gold") %>% rep(each = 3)
lty <- c(1, 2, 3, 4, 2, 3, 4, 1, 3, 4, 1, 2)
p1 <-
  xyplot(
    AVE + mAVE + MedAE + MedSE + MedE + MedSDR ~ p, data = cross_validation, groups = m,
    type = "l", col = col, lty = lty, lwd = 3, xlab = "Model formulation", ylab = "",
    key = list(lines = list(col = col, lty = lty, lwd = 3), columns = 4, 
               text = list(levels(cross_validation$m))),
    scales = list(x = list(relation = "same"), y = list(relation = "free")), layout = c(2, 3),
    panel = function (...) {
      panel.grid(h = -1, v = -1)
      panel.xyplot(...)
    })
png("../res/fig/cross-validation.png", width = 480 * 4, height = 480 * 5, res = 72 * 3)
p1
dev.off()
```

Check model coefficients.

```{r, eval=FALSE}
model_fit
```
