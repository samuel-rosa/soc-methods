---
title: "Pedotransfer functions for prediction and harmonization of carbon and organic matter content data in southern Brazil: source code"
author: "Alessandro Samuel-Rosa"
date: "12 October 2017"
url: "https://docs.google.com/document/d/13CJdr6huHhpuwKMfz_u03m8dJE3_xLqhmS7lwc5Y5yE/edit?usp=sharing"
# bibliography: "/home/alessandrorosa/Dropbox/jabref/biblio.bib"
# csl: pesquisa-agropecuaria-brasileira.csl
output: html_document
---

```{r}
# load packages
library(dplyr)
library(magrittr)
library(grid)
library(latticeExtra)
library(quantreg)
library(glue)
```

# Material and Methods

## Soil data

The data can be downloaded from the Free Brazilian Repository for Open Soil Data. The dataset identification code is `ctb0029`. Here we use a copy of the data stored in folder `data`.

We create categorical variables using the clay content (`argila_naoh_esferas_pipeta`) and the organic matter content determined at the commercial soil analysis laboratory of the Universidade Federal de Santa Maria (`matorg_dicromato_30min80_eam`). For the latter, the classification is performed using the three classes used for fertilizer recommendations in Rio Grande do Sul and Santa Catarina.

```{r, echo=FALSE, message=FALSE}
camada <- readr::read_csv(
  '../data/camada.csv', locale = readr::locale(decimal_mark = ','), comment = '#unidade', na = "-")
camada <-
  camada %>% 
  mutate(textura = ifelse(argila_naoh_esferas_pipeta <= 250, '0-250', '251-500')) %>% 
  mutate(textura = ifelse(argila_naoh_esferas_pipeta > 500, '501-1000', textura)) %>% 
  mutate(textura = as.factor(textura)) %>% 
  mutate(matorg = ifelse(matorg_dicromato_30min80_eam <= 25, '<25', '26-50')) %>%
  mutate(matorg = ifelse(matorg_dicromato_30min80_eam > 50, '>50', matorg)) %>%
  mutate(matorg = as.factor(matorg)) %>% 
  mutate(observacao_id = as.factor(observacao_id)) %>% 
  rename(clay = argila_naoh_esferas_pipeta) %>% 
  rename(toc = carbono_fornalha_1min950_cgdct) %>%
  rename(oc = carbono_dicromato_30min150_mohr) %>% 
  rename(tom = matorg_fornalha_120min360_massa) %>% 
  rename(om = matorg_dicromato_30min80_eam)
camada
```

Data on soil observations if processed. Land use info, `terra_usoatual`, is reclassified using FAO guidelines for soil description. The following codes are used:

* FS (Floresta): Semi-deciduous forest (vegetation slightly disturbed)
* U (Vegetação secundária): Not used and not managed, vegetation strongly disturbed by clearing, burning, ploughing (secondary vegetation, mix of semi-deciduous shrubs and tall grassland)
* AA (Agricultura): Annual field cropping
* FP (Silvicultura): Plantation forestry
* HE (Campo nativo): Animal husbandry (extensive grazing)

```{r, echo=FALSE, message=FALSE}
observacao <- readr::read_csv(
  '../data/observacao.csv', locale = readr::locale(decimal_mark = ','), comment = '#unidade', na = '-')
observacao <-
  observacao %>% 
  mutate(terra_usoatual = gsub('Floresta', 'FS', .data$terra_usoatual)) %>% 
  mutate(terra_usoatual = gsub('Vegetação secundária', 'U', .data$terra_usoatual)) %>%
  mutate(terra_usoatual = gsub('Agricultura', 'AA', .data$terra_usoatual)) %>%
  mutate(terra_usoatual = gsub('Silvicultura', 'FP', .data$terra_usoatual)) %>%
  mutate(terra_usoatual = gsub('Campo nativo', 'HE', .data$terra_usoatual))
observacao
```

Compute some summary statistics: number of taxonomic classes, and range of clay content.

```{r, eval = FALSE}
data.frame(
  taxa = nlevels(as.factor(observacao$taxon_sibcs_2009)),
  min_clay = min(camada$clay, na.rm = TRUE),
  max_clay = max(camada$clay, na.rm = TRUE)
  )
```

### TODO: Figure 1

Location of soil observations used in this study.

### Figure 2

Key characteristics of the soil samples, such as the clay content and sampling depth, and their sampling sites, such as the soil classification and type of land use and occupation.

```{r, eval = FALSE}
p1 <- histogram(
  ~ clay, camada, xlab = 'Clay content (g/kg)', ylab = 'Percent of total', 
  col = 'lightgray',
  panel = function (...) {
    lattice::panel.grid(v = -1, h = -1)
    lattice::panel.histogram(...)
  },
  page = function (n) {
    grid.text(label = "A)", x = unit(0.04, "npc"), y = grid::unit(0.95, "npc"))
  }) +
  latticeExtra::layer(panel.abline(v = c(250, 500), lty = 'dotted'))
p2 <- histogram(
  ~ profund_sup, camada, xlab = 'Sampling depth (cm)', ylab = 'Percent of total', col = 'lightgray',
  panel = function (...) {
    lattice::panel.grid(v = -1, h = -1)
    lattice::panel.histogram(...)
  },
  page = function (n) {
    grid.text(label = "B)", x = unit(0.04, "npc"), y = grid::unit(0.95, "npc"))
  })
p3 <- barchart(
  observacao$taxon_sibcs_2009, xlab = 'Soil classification', ylab = 'Percent of total', horizontal = FALSE, 
  col = 'lightgray', scales = list(x = list(rot = 60)),
  panel = function (...) {
    lattice::panel.grid(h = -1, v = 0)
    lattice::panel.barchart(...)
  },
  page = function (n) {
    grid.text(label = "C)", x = unit(0.04, "npc"), y = grid::unit(0.95, "npc"))
  })
p4 <- barchart(
  observacao$terra_usoatual, xlab = 'Land use and ocupation', ylab = 'Percent of total', horizontal = FALSE, 
  col = 'lightgray',
  panel = function (...) {
    lattice::panel.grid(h = -1, v = 0)
    lattice::panel.barchart(...)
  },
  page = function (n) {
    grid.text(label = "D)", x = unit(0.04, "npc"), y = grid::unit(0.95, "npc"))
  })
png("../res/fig/features-soil-samples.png", width = 480 * 4, height = 480 * 4, res = 72 * 3)
gridExtra::grid.arrange(p1, p2, p3, p4, ncol = 2)
dev.off()
```

## Analytical methods

Includes a description of the four analytical methods used:

1. Total organic carbon (TOC) by dry combustion
2. Organic carbon (OC) by wet digestion
3. Organic matter (OM) by wet digestion
4. Total organic matter (TOM) by loss on ignition

### Figure 3

Empirical probability density of carbon (A and B) and organic matter (C and D) content in soil samples according to the four analytical methods and the theoretical normal probability density function (dashed line).

```{r, eval = FALSE}
l <- layer(
  panel.mathdensity(
    dmath = dnorm, args = list(mean = mean(x, na.rm = TRUE), sd = sd(x, na.rm = TRUE)), n = length(x), 
    col = 'black', lty = 'dashed'))
p1 <- histogram(
  ~ toc, camada, 
  xlab = expression('Total organic carbon (TOC), g kg'^'-1'), col = 'lightgray', type = "density", 
  panel = function (...) {
    panel.grid(v = -1, h = -1)
    panel.histogram(...)
  },
  page = function (n) {
    grid.text(label = "A)", x = unit(0.04, "npc"), y = grid::unit(0.95, "npc"))
  }) + l
p2 <- histogram(
  ~ oc, camada, 
  xlab = expression('Organic carbon (OC), g kg'^'-1'), col = 'lightgray', type = "density", 
  panel = function (...) {
    panel.grid(v = -1, h = -1)
    panel.histogram(...)
  },
  page = function (n) {
    grid.text(label = "B)", x = unit(0.04, "npc"), y = grid::unit(0.95, "npc"))
  }) + l
p3 <- histogram(
  ~ om, camada, 
  xlab = expression('Organic matter (OM), g dm'^'-3'), col = 'lightgray', type = "density", 
  panel = function (...) {
    panel.grid(v = -1, h = -1)
    panel.histogram(...)
  },
  page = function (n) {
    grid.text(label = "C)", x = unit(0.04, "npc"), y = grid::unit(0.95, "npc"))
  }) + l
p4 <- histogram(
  ~ tom, camada, 
  xlab = expression('Total organic matter (TOM), g kg'^'-1'), col = 'lightgray', type = "density", 
  panel = function (...) {
    panel.grid(v = -1, h = -1)
    panel.histogram(...)
  },
  page = function (n) {
    grid.text(label = "D)", x = unit(0.04, "npc"), y = grid::unit(0.95, "npc"))
  }) + l
png("../res/fig/carbon-histograms.png", width = 480 * 4, height = 480 * 4, res = 72 * 3)
gridExtra::grid.arrange(p1, p2, p3, p4, ncol = 2)
dev.off()
```

# Pedotransfer functions

## Quantile regression

## Performance assessment

# Results

## Carbon and organic matter data

### Figure 4

Scatter plot matrix of the soil carbon and organic matter content measured using four different analytical methods and their relation to the total clay content and class (0-250, 251-500, 501-1000 g kg-1). The solid line represents a perfect 1:1 linear relation, while the dashed line is the observed empirical linear relation between variables.

```{r, eval = FALSE}
png("../res/fig/scatter-plot-matrix.png", width = 480 * 4, height = 480 * 4, res = 72 * 3)
camada %>% 
  select(toc, oc, om, tom, clay) %>% 
  splom(groups = camada$textura, grid = TRUE, auto.key = list(columns = 3), xlab = '',
        varnames = c(expression(atop('TOC', 'g kg'^'-1')), expression(atop('OC', 'g kg'^'-1')),
                     expression(atop('OM', 'g dm'^'-3')), expression(atop('TOM', 'g kg'^'-1')),
                     expression(atop('Clay', 'g kg'^'-1')))) +
  latticeExtra::layer(panel.abline(a = 0, b = 1)) +
  latticeExtra::layer(panel.lmline(x = x, y = y, lty = 'dashed'))
dev.off()
```

# Results and Discussion

```{r, echo=FALSE}
# Define formulas
soil_vars <- c("toc", "oc", "om", "tom")
soil_vars <- expand.grid(soil_vars, soil_vars, stringsAsFactors = FALSE)[, 2:1]
soil_vars <- soil_vars[!soil_vars[, 1] == soil_vars[, 2], ]
# One predictor
forms1 <- data.frame(y = soil_vars[, 1], x1 = soil_vars[, 2])
forms1 <- apply(forms1, 1, function (x) reformulate(x[2:ncol(forms1)], x[1]))
# Two predictors
forms2 <- data.frame(y = soil_vars[, 1], x1 = soil_vars[, 2], x2 = glue("I({soil_vars[, 2]}^2)"))
forms2 <- apply(forms2, 1, function (x) reformulate(x[2:ncol(forms2)], x[1]))
# Three predictors
forms3 <- data.frame(y = soil_vars[, 1], x1 = soil_vars[, 2], x2 = glue("I({soil_vars[, 2]}^2)"), x3 = "clay")
forms3 <- apply(forms3, 1, function (x) reformulate(x[2:ncol(forms3)], x[1]))
# names
names(forms1) <- sapply(forms1, function (x) x)
names(forms2) <- sapply(forms2, function (x) x)
names(forms3) <- sapply(forms3, function (x) x)
```

We implement weighted least squares to estimate betas, make predictions and estimate prediction error
variances. Estimates are compared with the output of `lm` and `predict.lm`. This is usefull to understand the
estimation equations and their differences compared to ordinary least squares.

```{r, eval=FALSE}
# Temporary data
tmp_data <- camada[1:105, ]

# Test observations
i <- 96:105

# Estimate model using lm
fit <- lm(tom ~ om + clay, data = tmp_data[-i, ], weights = 1/om)
pred <- predict(fit, tmp_data[i, c("om", "clay")], se.fit = TRUE)

# Dependent variable
Y <- tmp_data[-i, "tom"] %>% as.matrix()

# Predictor variables
X <- data.frame(x0 = 1, tmp_data[-i, c("om", "clay")]) %>% as.matrix()

# Weights
W <- matrix(0, ncol = nrow(X), nrow = nrow(X))
diag(W) <- 1 / X[, "om"]

# Estimate betas: (X'WX)⁻¹X'WY
b_hat <- solve(t(X) %*% W %*% X) %*% t(X) %*% W %*% Y %>% drop()
data.frame(b_hat = b_hat, lm = fit$coefficients)

# Residual sum of squares
rss <- sum(diag(W) * (Y - X %*% drop(b_hat))^2) / (nrow(X) - ncol(X))
data.frame(rss, lm = summary(fit)$sigma^2)

# Prediction at a point
x0 <- data.frame(x0 = 1, tmp_data[i, c("om", "clay")]) %>% as.matrix()
y_hat <- x0 %*% drop(b_hat)
data.frame(y_hat = y_hat, lm = pred$fit)

# Prediction error variance: RSS * (1 + x0 (X'X)⁻¹x0')
pev <- rss * (1 + x0 %*% solve(t(X) %*% W %*% X) %*% t(x0)) %>% diag()
data.frame(pev = pev, lm = pred$se.fit^2 + pred$residual.scale^2)
```

```{r}
all_forms <- list(forms1, forms2, forms3)
dataset <- camada[1:105, ]
full_cv <- list()
for (k in 1:length(all_forms)) {
  forms <- all_forms[[k]]
  cv <- list()
  for (j in 1:length(forms)) {
    f <- forms[[j]]
    y <- dataset[[soil_vars[j, 1]]]
    x <- dataset[[soil_vars[j, 2]]]
    w <- 1 / x
    err <- data.frame(rq = NA_real_, lm = NA_real_)
    # Leave-one-out cross-validation
    for (i in 1:nrow(dataset)) {
      # quantile regression
      rq_fit <- rq(f, data = dataset[-i, ], method = "fn")
      err[i, "rq"] <- predict(rq_fit, dataset[i, ]) - y[i]
      # weighted least squares regression
      lm_fit <- lm(f, data = dataset[-i, ], weights = w[-i])
      err[i, "lm"] <- predict(lm_fit, dataset[i, ]) - y[i]
    }
    # Error statistics
    resid <- mean(y) - y
    err_sqr <- err^2
    err_abs <- abs(err)
    cv[[j]] <- data.frame(
      ME = colMeans(err),
      MAE = colMeans(err_abs),
      MSE = colMeans(err_sqr), 
      AVE = 1 - (colSums(err_sqr) / sum(resid^2))
    )
  }
  names(cv) <- names(forms)
  cv <- do.call(rbind, cv) %>% round(3)
  full_cv[[k]] <- cv
  write.csv(cv, file = glue("../res/tab/cv-{k}-predictor.csv"))
}
names(full_cv) <- 1:3
full_cv <- do.call(rbind, full_cv)
```

```{r}
full_cv$p <- rep(c("y ~ x0 + x1", "y ~ x0 + x1 + x2", "y ~ x0 + x1 + x2 + x3"), each = 24) %>% as.factor()
full_cv$m <- rep(c("Quantile (median) regression", "Weighted least squares regression"), nrow(full_cv) / 2)
full_cv$y <- rep(soil_vars[, 1], each = ncol(err)) %>% rep(3) %>% as.factor()
full_cv$x <- rep(soil_vars[, 2], each = ncol(err)) %>% rep(3) %>% as.factor()
full_cv$id <- glue("{full_cv$m}({full_cv$y} ~ {full_cv$x})") %>% toupper() %>% as.factor()
full_cv$id2 <- glue("{full_cv$y} ~ {full_cv$x}") %>% toupper() %>% as.factor()
```

```{r, fig.asp=1}
col <- c("dodgerblue", "magenta", "olivedrab", "gold") %>% rep(each = 3)
lty <- c(1, 2, 3, 4, 2, 3, 4, 1, 3, 4, 1, 2)
p1 <-
xyplot(
  AVE + MSE + MAE + ME ~ as.factor(p) | m, full_cv, groups = id2,  type = "l", col = col, lty = lty, lwd = 3,
  xlab = "Model formulation", scales = list(x = list(relation = "same"), y = list(relation = "sliced")),
  key = list(lines = list(col = col, lty = lty, lwd = 3), columns = 4, text = list(levels(full_cv$id2))),
  panel = function (...) {
    panel.grid(h = -1, v = 0)
    panel.xyplot(...)
  })
p1 <- 
  latticeExtra::useOuterStrips(
    p1, strip = lattice::strip.custom(bg = "bisque"), strip.left = lattice::strip.custom(bg = "lightblue"))
p1$aspect.ratio <- 1
lim <- 
  apply(full_cv[1:4], 2, function (x) by(x, full_cv$m, range)) %>% 
  sapply(function (x) c(x) %>% extendrange)
p1$y.limits <- lim[, rep(ncol(lim):1, each = 2)] %>% as.data.frame() %>% as.list()
png("../res/fig/cross-validation.png", width = 480 * 4, height = 480 * 6, res = 72 * 3)
p1
dev.off()
```


```{r, eval=FALSE}
densidade <- 
  read.table("../data/densidade.csv", sep = "\t", dec = ",", head = TRUE) %>% 
  reshape(direction = "long", idvar = "id", varying = list(4:6), v.names = "d") %>% 
  mutate(id = as.factor(id), clay = as.numeric(clay))
fit1 <- nlme::lme(d ~ som + clay, data = densidade, random = ~1|id)
summary(fit)
plot(fit)
nlme::intervals(fit)
cbind(fit2$fitted, obs = densidade$d, fit = fitted(fit2)) %>% round(3)

fit2 <- lm(d ~ som + clay, data = densidade)
```

```{r, fig.asp=1, eval=FALSE}
mo <- log1p(round((camada$mo_wet * camada$densidade) / 10, 1))
clay <- camada$argila_naoh_pipeta
dens <- camada$densidade
plot(dens ~ clay)
fit <- lm(dens ~ mo*clay)
summary(fit)
```

```{r, eval=FALSE}
plot(fit, 1)
```


```{r, fig.asp=1, eval=FALSE}
plot(fit$fitted.values ~ dens)
abline(lm(fit$fitted.values ~ dens), col = "red")
abline(a = 0, b = 1)
```



```{r calibrate_models, echo=FALSE, eval=FALSE}
# Function to calibrate models for different values of tau
calibrate_models <-
  function (tau) {
    fit <- list()
    for (i in 1:length(forms)) {
      fit[[i]] <- rq(forms[[i]], tau = tau, data = camada, method = 'fn')
    }
    names(fit) <- names(forms)
    fit
  }
```

```{r, echo=FALSE, eval=FALSE}
# Calibrate models for tau = {0.025, 0.5, 0.975}
fit_lower <- calibrate_models(0.025)
fit_median <- calibrate_models(0.5)
fit_upper <- calibrate_models(0.975)
```

```{r prepare_beta_table, echo=FALSE, eval=FALSE}
# Function to prepare table with estimated model parameters (betas)
prepare_beta_table <-
  function (fit) {
    betas <- lapply(fit, function (x) summary(x)$coefficients)
    betas <- do.call(rbind, betas) %>% round(4)
    betas <- data.frame(PTF = rep(names(forms), each = 2), Beta = rownames(betas), betas)
    betas$PTF <- glue('**{betas$PTF}**')
    betas$PTF[seq(2, length(betas$PTF), 2)] <- ''
    rownames(betas) <- NULL
    colnames(betas)[3:5] <- c('Estimate', 'Lower', 'Upper')
    colnames(betas) <- glue('**{colnames(betas)}**')
    betas
  }
```

```{r, echo=FALSE, message=FALSE, warning=FALSE, eval=FALSE}
# Table with estimated model parameters por tau = 0.5
tau <- 0.5
betas_median <- prepare_beta_table(fit_median)
panderOptions('round', rep(4, ncol(betas_median)))
panderOptions('table.split.cells', rep(100 / ncol(betas_median), ncol(betas_median)))
pander(betas_median, caption = glue('(\\#tab:coefficients-median) Estimated coefficients of carbon and organic matter pedotransfer functions and their respective confidence interval. Coefficients are as follows: $\\Beta_0$ -- intercept, $\\Beta_1$ -- soil carbon and organic matter content.'))
```

```{r get_y, echo=FALSE, eval=FALSE}
# Function to extract the name of the dependent variable in a formula
get_y <- function (form) {
  terms(form, simplify = T)[[2]] %>% as.character()
}
```

```{r cross-validation, echo=FALSE, eval=FALSE}
# Cross-validate models
cv <- list()
for (j in 1:length(forms)) {
  err <- vector()
  for (i in 1:nrow(camada)) {
    y <- camada[[get_y(forms[[j]])]]
    resid <- mean(y) - y
    cv_fit <- rq(forms[[j]], data = camada[-i, ], method = 'fn')
    err[i] <- predict(cv_fit, camada[i, ]) - y[i]
  }
  cv[[j]] <- data.frame(
    ME = mean(err),
    MedE = median(err),
    MAE = mean(abs(err)),
    MedAE = median(abs(err)),
    MSE = mean(err * err), 
    MedSE = median(err * err), 
    AVE = 1 - (sum(err * err) / sum(resid * resid)))
}
names(cv) <- names(forms)
cv <- do.call(rbind, cv) %>% round(4)
```

```{r, echo=FALSE, eval=FALSE}
colnames(cv) <- glue('**{colnames(cv)}**')
panderOptions('round', rep(4, ncol(cv)))
panderOptions('table.split.cells', rep(100 / ncol(cv), ncol(cv)))
pander(cv, caption = '(\\#tab:cross-validation) Leave-one-out cross-validation results of soil carbon and organic matter pedotransfer functions. Error statistics are as follows: ME -- mean error, MedE -- median error, MAE -- mean absolute error, MedAE -- median absolute error, MSE -- mean square error, MedSE -- median square error, AVE -- amount of variance explained.')
```

The estimated parameters of the quantile regressions for the lower ($\tau = 0.025$) and upper ($\tau = 0.975$) 
bounds of the 90% prediction interval of the carbon and organic matter pedotransfer functions are shown in 
Tables \@ref{tab:coefficients-lower} and \@ref{tab:coefficients-upper}, respectively.

```{r, echo=FALSE, message=FALSE, warning=FALSE, eval=FALSE}
# Table with estimated model parameters por tau = 0.025
tau <- 0.025
betas_lower <- prepare_beta_table(fit_lower)
panderOptions('round', rep(4, ncol(betas_lower)))
panderOptions('table.split.cells', rep(100 / ncol(betas_lower), ncol(betas_lower)))
pander(betas_lower, caption = glue('(\\#tab:coefficients-lower) Estimated coefficients for computing the lower bound ($\\tau = {tau}$) of the prediction interval of carbon and organic matter pedotransfer functions. Coefficients are as follows: $\\Beta_0$ -- intercept, $\\Beta_1$ -- soil carbon and organic matter content.'))
```

```{r, echo=FALSE, message=FALSE, warning=FALSE, eval=FALSE}
# Table with estimated model parameters por tau = 0.975
tau <- 0.975
betas_upper <- prepare_beta_table(fit_upper)
panderOptions('round', rep(4, ncol(betas_upper)))
panderOptions('table.split.cells', rep(100 / ncol(betas_upper), ncol(betas_upper)))
pander(betas_upper, caption = glue('(\\#tab:coefficients-upper) Estimated coefficients for computing the upper bound ($\\tau = {tau}$) of the prediction interval of carbon and organic matter pedotransfer functions. Coefficients are as follows: $\\Beta_0$ -- intercept, $\\Beta_1$ -- soil carbon and organic matter content.'))
```

# References